{
  "model": "gpt2-xl",
  "pipeline": "text-generation",
  "load_in_8bit": true,
  "max_new_tokens": 64,
  "temperature": 0.1
}
