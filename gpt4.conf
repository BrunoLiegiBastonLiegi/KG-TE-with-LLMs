{
  "model": "gpt-4",
  "pipeline": "text-generation",
  "max_new_tokens": 64,
  "temperature": 0.1
}
