{
  "gpt2 (KB top-5) T=0.1 prompt=base_no_exaples": {
    "P": 0.26595744680851063,
    "R": 0.2336448598130841,
    "F1": 0.24875621890547264
  },
  "gpt2-xl (KB top-5) T=0.1 prompt=base_no_exaples": {
    "P": 0.2782608695652174,
    "R": 0.3190031152647975,
    "F1": 0.29724238026124816
  },
  "falcon-7b (KB top-5) T=0.1 prompt=base_no_exaples": {
    "P": 0.3179166666666667,
    "R": 0.4753894080996885,
    "F1": 0.38102372034956306
  },
  "falcon-40b (KB top-5) T=0.1 prompt=base_no_exaples": {
    "P": 0.2821939586645469,
    "R": 0.4423676012461059,
    "F1": 0.3445765590876001
  },
  "llama-13b (KB top-5) T=0.1 prompt=base_no_exaples": {
    "P": 0.32205683355886333,
    "R": 0.44485981308411215,
    "F1": 0.3736263736263736
  },
  "llama-65b (KB top-5) T=0.1 prompt=base_no_exaples": {
    "P": 0.31951640759930916,
    "R": 0.46105919003115264,
    "F1": 0.37745473093598575
  },
  "gpt-3.5-turbo (KB top-5) T=0.1 prompt=base_no_exaples": {
    "P": 0.2808848080133556,
    "R": 0.4193146417445483,
    "F1": 0.33641589602599353
  },
  "gpt-4 (KB top-5) T=0.1 prompt=base_no_exaples": {
    "P": 0.34405594405594403,
    "R": 0.45981308411214955,
    "F1": 0.3936
  }
}