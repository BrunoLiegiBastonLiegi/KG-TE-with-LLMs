{
  "model": "gpt-3.5-turbo",
  "pipeline": "text-generation",
  "max_new_tokens": 64,
  "temperature": 0.1,
  "openai": true
}
